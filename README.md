# Automated Podcast Transcription and Topic Segmentation

##  Project Overview

The **Automated Podcast Transcription & Topic Segmentation** project aims to build an end-to-end AI system that can:

- Convert podcast audio into accurate transcripts.
- Detect topic boundaries automatically.
- Segment the transcript into meaningful chapters.
- Extract keywords and summaries for each topic.
- Provide a UI to navigate the podcast episode by topics & timestamps.
- Display segment-level visual analytics.

This project focuses on applying **AI, Speech Processing, NLP, and ML engineering** to create a practical real-world audio intelligence tool.

## Project Objectives

### 1. Transcription (Speech-to-Text)
- Convert long podcast audio files into text using ASR models.
- Support noisy, multi-speaker, real-world audio.
- Produce timestamps for each transcribed segment.

### 2. Topic Segmentation
- Detect shifts in content and break the transcript into chapters.
- **Techniques Used:**
  - TextTiling (Classic NLP)
  - Embedding similarity (BERT / Sentence Transformers)
  - Change-point detection methods

### 3. Summarization & Keyword Extraction
Generate per-topic:

- Short abstractive summaries *(DistilBART)*
- Keywords and keyphrases *(KeyBERT)*
- Sentiment Analysis *(TextBlob)*

### 4. UI for Navigation
- Show transcript & segment list.

## System Architecture

Audio Input â†’ Preprocessing â†’ Transcription (ASR) â†’ Transcript Cleaning â†’ Embedding Model â†’ Topic Segmentation â†’ Segment Summaries & Keywords â†’ Indexing â†’ UI (Search, Playback, Visualization)

- Clickable segments â†’ jump to timestamp.
- Playback visualization (Sentiment Timeline, Keyword Clouds).

## ðŸ›  Tech Stack

### Core
- Python 3.9+
- Whisper (OpenAI): ASR
- Librosa, PyDub, ffmpeg: Audio processing

### NLP
- NLTK (TextTiling)
- HuggingFace Transformers (Summarization)
- Sentence Transformers (Semantic Similarity)
- KeyBERT (Keywords)
- TextBlob (Sentiment Analysis)

### Visualization & UI
- Flask (Backend)
- Plotly (Interactive visualizations)
- HTML/CSS/JS (Frontend)

### Storage
- JSON (Transcript & metadata storage)

##  Folder Structure
Podcast_Transcription1/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Source audio files
â”‚ â”œâ”€â”€ transcripts/
â”‚ â”œâ”€â”€ segmented_topics/
â”‚ â””â”€â”€ final_output/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ transcriber.py # Whisper model wrapper
â”‚ â”œâ”€â”€ data_loader.py # MP3 â†’ WAV & audio processing
â”‚ â”œâ”€â”€ semantic_segmenter.py # BERT-based segmentation
â”‚ â”œâ”€â”€ content_processor.py # Summary, Keywords & Sentiment
â”‚ â”œâ”€â”€ file_utils.py # Path helpers
â”‚ â””â”€â”€ web_app/
â”‚ â”œâ”€â”€ templates/
â”‚ â”‚ â”œâ”€â”€ index.html # UI Page 1
â”‚ â”‚ â””â”€â”€ player.html # Player with visualizations
â”‚ â””â”€â”€ app.py # Flask backend
â”‚
â”œâ”€â”€ main.py # Step 1: Transcription
â”œâ”€â”€ run_segmentation.py # Step 2: Topic segmentation
â”œâ”€â”€ run_processing.py # Step 3: Summaries & keywords
â”œâ”€â”€ evaluate_accuracy.py # WER calculation
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Documentation

## âš™ Installation & Setup

### 1. Clone the Repository
git clone <repo-url>
cd Podcast_Transcription1

### 2. Create Virtual Environment
python -m venv venv
source venv/bin/activate      # Mac/Linux
.env\Scriptsctivate       # Windows

### 3. Install Dependencies
pip install flask transformers torch torchaudio sentence-transformers textblob keybert jiwer plotly pydub nltk scikit-learn openai-whisper

### 4. Install FFmpeg
Required for audio processing.
- Windows: download from gyan.dev  
- Mac: brew install ffmpeg

##  How to Run

### Run the Pipeline

# Step 1: Transcribe (Audio â†’ Text)
python main.py

# Step 2: Segment (Text â†’ Topics)
python run_segmentation.py

# Step 3: Generate Summaries/Keywords
python run_processing.py

### Launch Web UI

python src/web_app/app.py

Then open in browser: http://127.0.0.1:5000

