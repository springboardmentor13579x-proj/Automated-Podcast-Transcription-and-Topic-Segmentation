# ğŸ™ï¸ Automated Podcast Transcription & Analysis System

An end-to-end pipeline that converts podcast audio â†’ clean transcript â†’ topic-based segments â†’ summaries â†’ keyword extraction â†’ timestamp-aligned insights.

---

## ğŸš€ Features Completed

### **1ï¸âƒ£ Audio Transcription (Whisper ASR)**

* Batch transcription for multiple audio files.
* Whisper (`openai-whisper`) used for speech-to-text.
* Output stored as structured JSON:

```json
{
  "audio_file": "...",
  "language": "en",
  "segments": [
    { "start": 0.0, "end": 5.2, "text": "..." }
  ]
}
```

---

### **2ï¸âƒ£ Transcript Cleaning**

* Removes filler tokens, unwanted characters, broken spacing.
* Cleaned transcripts stored as:

```
Bad Habit_cleaned.json
Confident_cleaned.json
...
```

---

### **3ï¸âƒ£ Topic Segmentation**

Implemented two algorithms:

#### ğŸ”¹ **TextTiling (NLTK)**

* Paragraph-like segmentation based on lexical cohesion.

#### ğŸ”¹ **BERT Semantic Segmentation**

* Uses SentenceTransformers (MiniLM-L6-v2).
* Splits based on semantic similarity drop.
* Produces more accurate topic shifts.

Outputs stored as:

```
Bad Habit_cleaned_segments.json
Confident_cleaned_segments.json
...
```

Each file includes:

```json
{
  "texttiling_segments": [...],
  "bert_segments": [...]
}
```

---

### **4ï¸âƒ£ Keyword Extraction (YAKE)**

* Extracts top keywords for each segment.
* Helps in indexing and search.

---

### **5ï¸âƒ£ Summarization (T5-small)**

* Summarizes each segment using HuggingFace T5 model.
* Generates concise 20â€“80 token summaries.

---

### **6ï¸âƒ£ Timestamp Alignment**

* Segment text aligned with Whisper timestamps.
* Start & end times included for navigation (UI ready).

---

### **7ï¸âƒ£ Final Output (Per File)**

Each audio file generates a structured summary file:

```
Bad Habit_segments.json
Confident_segments.json
...
```

Example segment:

```json
{
  "segment_id": 1,
  "text": "...",
  "summary": "...",
  "keywords": ["...", "..."],
  "start_time": 12.40,
  "end_time": 34.52
}
```

---

### **8ï¸âƒ£ WER Evaluation**

* Evaluates accuracy against human-written transcripts.
* Uses `jiwer` library.
  Example:

```
WER for Bad Habit: 0.094
```

---

## ğŸŒ Backend 

### **Tech Stack**

* Node.js
* Express.js
* MongoDB (Local)
* Mongoose ODM

---

### **Backend Features**

* REST API for podcasts & segments
* MongoDB persistence for:

  * Podcasts
  * Segments (timestamps, keywords, summaries)
* Search & keyword filtering support

---

### **API Endpoints**

#### ğŸ“Œ Podcasts

```
GET /api/podcasts
```

Returns all uploaded podcasts

---

#### ğŸ“Œ Segments by Podcast

```
GET /api/podcasts/:podcastId/segments
```

Optional query params:

```
?keyword=trauma
?search=brain
```

---

### **MongoDB Schema Overview**

#### Podcast

* title
* fileName
* audioUrl
* createdAt

#### Segment

* podcastId (ObjectId)
* segmentId
* text
* summary
* keywords
* startTime
* endTime

---

## ğŸ“‚ Project Structure

```bash
automated-podcast-transcription/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ db.js
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Podcast.js
â”‚   â”‚   â””â”€â”€ Segment.js
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ podcastRoutes.js
â”‚   â”‚   â””â”€â”€ segmentRoutes.js
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ importSegments.js
â”‚   â”œâ”€â”€ server.js
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ transcripts/
â”‚   â””â”€â”€ segments/
â”‚
â”œâ”€â”€ src/  # Python pipeline
â”‚   â”œâ”€â”€ transcription/
â”‚   â””â”€â”€ segmentation/
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ Bad Habit_segments.json
â”‚   â”œâ”€â”€ Confident_segments.json
â”‚   
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Install FFmpeg

Ensure FFmpeg is installed and added to PATH.

---

## â–¶ï¸ Running the Pipeline

### **Transcription**

```bash
python -m src.transcription.batch_transcriber
```

### **Segmentation**

```bash
python -m src.segmentation.batch_segmenter
```

### **Keywords + Summaries + Timestamps**

```bash
python -m src.segmentation.batch_keyword_summarizer
```

### **WER Evaluation**

```bash
python -m src.transcription.batch_wer_evaluator
```

### **MongoDB Setup (Local)**

* Install MongoDB Community Edition
* Ensure MongoDB service is running

Check:

```bash
mongod
```

---

### **Backend Setup**

```bash
cd backend
npm install
```

Create `.env` file:

```env
PORT=5000
MONGO_URI=mongodb://127.0.0.1:27017/podcast-analyzer
```

---

### **Import Processed Segments into MongoDB**

```bash
node scripts/importSegments.js
```

---

### **Start Backend Server**

```bash
npm run dev
```

Server runs at:

```
http://localhost:5000
```

---

## ğŸ” Testing API

* `http://localhost:5000/api/podcasts`
* `http://localhost:5000/api/podcasts/<PODCAST_ID>/segments`
* `http://localhost:5000/api/podcasts/<PODCAST_ID>/segments?keyword=trauma`

---

## âš™ï¸ Setup Instructions 

### **1ï¸âƒ£ Clone Repository**

```bash
git clone <repo-url>
cd automated-podcast-transcription
```

---

### **2ï¸âƒ£ Python Pipeline Setup**

```bash
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

Ensure **FFmpeg** is installed and added to PATH.

---

### **3ï¸âƒ£ Run Python Processing**

```bash
python -m src.transcription.batch_transcriber
python -m src.segmentation.batch_segmenter
python -m src.segmentation.batch_keyword_summarizer
```

---

### **4ï¸âƒ£ MongoDB Setup (Local)**

* Install MongoDB Community Edition
* Ensure MongoDB service is running

Check:

```bash
mongod
```

---

### **5ï¸âƒ£ Backend Setup**

```bash
cd backend
npm install
```

Create `.env` file:

```env
PORT=5000
MONGO_URI=mongodb://127.0.0.1:27017/podcast-analyzer
```

---

### **6ï¸âƒ£ Import Processed Segments into MongoDB**

```bash
node scripts/importSegments.js
```

---

### **7ï¸âƒ£ Start Backend Server**

```bash
npm run dev
```

Server runs at:

```
http://localhost:5000
```

---

## ğŸ¯ Next Steps (Week 4 â€“ UI & Indexing)

* MERN-based transcript viewer.
* Search and keyword filtering.
* Segment jumping using timestamps.
* Interactive transcript navigation UI.

---

## ğŸ‘¨â€ğŸ’» Tech Stack Used

### **Python Backend**

* Whisper ASR
* NLTK
* Sentence Transformers
* YAKE
* HuggingFace Transformers
* JiWER

### Backend

* Node.js
* Express.js
* MongoDB
* Mongoose

### Frontend (Upcoming)

* React
* Tailwind CSS

---

## ğŸ“Œ Notes

* MongoDB is intentionally **local-only** for development
* No database files are pushed to Git (best practice)
* `.env` is required but not committed

## ğŸ¤ Acknowledgements

* OpenAI Whisper â€“ Speech-to-Text (ASR)
* HuggingFace Transformers â€“ T5 summarization
* Sentence-Transformers â€“ Semantic segmentation (MiniLM)
* NLTK â€“ TextTiling based segmentation
* YAKE â€“ Keyword extraction
* JiWER â€“ Word Error Rate (WER) evaluation
* Node.js â€“ Backend runtime environment
* Express.js â€“ REST API framework
* MongoDB â€“ NoSQL database
* Mongoose â€“ MongoDB object data modeling (ODM)


