# Automated Podcast Transcription and Topic Segmentation

## ğŸ“Œ Project Overview

The **Automated Podcast Transcription & Topic Segmentation** project aims to build an end-to-end AI system that can:

- Convert podcast audio into accurate transcripts.
- Detect topic boundaries automatically.
- Segment the transcript into meaningful chapters.
- Extract keywords and summaries for each topic.
- Provide a UI to navigate the podcast episode by topics & timestamps.
- Display segment-level visual analytics.

This project focuses on applying **AI, Speech Processing, NLP, and ML engineering** to create a practical real-world audio intelligence tool.

---

## ğŸ¯ Project Objectives

### 1. Transcription (Speech-to-Text)
- Convert long podcast audio files into text using ASR models.
- Support noisy, multi-speaker, real-world audio.
- Produce timestamps for each transcribed segment.

### 2. Topic Segmentation
- Detect shifts in content and break the transcript into chapters.
- **Techniques Used**
  - TextTiling (Classic NLP)
  - Embedding similarity (BERT / Sentence Transformers)
  - Change-point detection methods

### 3. Summarization & Keyword Extraction
Generate per-topic:

- Short abstractive summaries *(DistilBART)*
- Keywords and keyphrases *(KeyBERT)*
- Sentiment Analysis *(TextBlob)*

### 4. UI for Navigation
- Show transcript & segment list.

---

## ğŸ— System Architecture

```
Audio Input 
â†’ Preprocessing 
â†’ Transcription (ASR) 
â†’ Transcript Cleaning 
â†’ Embedding Model 
â†’ Topic Segmentation 
â†’ Segment Summaries & Keywords 
â†’ Indexing 
â†’ UI (Search, Playback, Visualization)
```

- Clickable segments â†’ jump to timestamp  
- Playback visualization (Sentiment Timeline, Keyword Clouds)

---

## ğŸ›  Tech Stack

### Core
- Python 3.9+
- Whisper (OpenAI)
- Librosa, PyDub, ffmpeg

### NLP
- NLTK (TextTiling)
- HuggingFace Transformers
- Sentence Transformers
- KeyBERT
- TextBlob

### Visualization & UI
- Flask
- Plotly
- HTML/CSS/JS

### Storage
- JSON structured metadata

---

## ğŸ“ Folder Structure

```
Podcast_Transcription1/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Source audio files
â”‚   â”œâ”€â”€ transcripts/
â”‚   â”œâ”€â”€ segmented_topics/
â”‚   â””â”€â”€ final_output/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ transcriber.py          # Whisper model wrapper
â”‚   â”œâ”€â”€ data_loader.py          # MP3 â†’ WAV audio loader
â”‚   â”œâ”€â”€ semantic_segmenter.py   # BERT-based segmentation
â”‚   â”œâ”€â”€ content_processor.py    # Summary, Keywords & Sentiment
â”‚   â”œâ”€â”€ file_utils.py           # Utility helpers
â”‚   â””â”€â”€ web_app/
â”‚       â”œâ”€â”€ templates/
â”‚       â”‚   â”œâ”€â”€ index.html      # Homepage UI
â”‚       â”‚   â””â”€â”€ player.html     # Transcript Player
â”‚       â””â”€â”€ app.py              # Flask server entrypoint
â”‚
â”œâ”€â”€ main.py                     # Step 1: Transcription
â”œâ”€â”€ run_segmentation.py         # Step 2: Topic Segmentation
â”œâ”€â”€ run_processing.py           # Step 3: Summary & Keywords
â”œâ”€â”€ evaluate_accuracy.py        # WER evaluation
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Project documentation
```

---

## âš™ Installation & Setup

### Clone Project
```bash
git clone <repo-url>
cd Podcast_Transcription1
```

### Create Environment
```bash
python -m venv venv
source venv/bin/activate      # Mac / Linux
.env\Scriptsctivate       # Windows
```

### Install Dependencies
```bash
pip install flask transformers torch torchaudio sentence-transformers textblob keybert jiwer plotly pydub nltk scikit-learn openai-whisper
```

### Install FFmpeg
- Windows: download from gyan.dev  
- macOS: `brew install ffmpeg`

---

## ğŸš€ Run Pipeline

```bash
# Step 1: Transcribe
python main.py

# Step 2: Segment Topics
python run_segmentation.py

# Step 3: Summaries + Keywords
python run_processing.py
```

### Launch Web UI

```bash
python src/web_app/app.py
```

Open browser:  
`http://127.0.0.1:5000`

---

## ğŸ“‚ Dataset Access
Due to the large size of the audio files, the dataset is hosted externally.

**ğŸ“¥ [https://drive.google.com/drive/folders/1yN69e6oQ2PJtBvhJ90a-YYtRfbIz7vcW?usp=drive_link] 

### **Setup Instructions**
1. Download the dataset from the link above.
2. Extract the folder.
3. Place the audio files in a folder named `audio_raw` inside the project root.
4. Update the `AUDIO_DIR` path in `.env` if necessary.

